{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6504606,"sourceType":"datasetVersion","datasetId":3758654}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport os\nimport cv2\nimport joblib\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nfrom collections import Counter\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-27T17:08:31.851275Z","iopub.execute_input":"2025-02-27T17:08:31.851552Z","iopub.status.idle":"2025-02-27T17:08:34.471695Z","shell.execute_reply.started":"2025-02-27T17:08:31.851524Z","shell.execute_reply":"2025-02-27T17:08:34.470840Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"train_labels = pd.read_csv('/kaggle/input/raf-db-dataset/train_labels.csv')\ntest_labels = pd.read_csv('/kaggle/input/raf-db-dataset/test_labels.csv')\n\nlabel_map = {2: \"fear\", 4: \"happy\", 5: \"sad\", 6: \"angry\"}\n\ntrain_labels = train_labels[train_labels[\"label\"].isin(label_map.keys())]\ntrain_labels[\"label\"] = train_labels[\"label\"].map(label_map)\n# Display the first few rows of the train labels to check the structure\nprint(train_labels)\n\ntest_labels = test_labels[test_labels[\"label\"].isin(label_map.keys())]\ntest_labels[\"label\"] = test_labels[\"label\"].map(label_map)\n# Display the first few rows of the train labels to check the structure\n# test_labels","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_map = {2: \"fear\", 4: \"happy\", 5: \"sad\", 6: \"angry\"}\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the labels CSV files\ntrain_labels = pd.read_csv('/kaggle/input/raf-db-dataset/train_labels.csv')\ntest_labels = pd.read_csv('/kaggle/input/raf-db-dataset/test_labels.csv')\n\n# Display the first few rows of the train labels to check the structure\nprint(train_labels.head())\n\nclasses = ['surprise', 'fear', 'disgust', 'happy', 'sad', 'angry', 'neutral']\n\n\nlabel_map = {label: (idx+1) for idx, label in enumerate(classes)}\n\nprint(label_map)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nfrom tqdm import tqdm\n\ndef load_data(dataset_dir, label_map, excluded_labels, new_label_map):\n    images = []\n    labels = []\n    \n    for label, idx in tqdm(label_map.items()):\n        if idx in excluded_labels:  # Skip excluded labels\n            continue\n        \n        folder_path = os.path.join(dataset_dir, str(idx))  \n        if not os.path.exists(folder_path):\n            print(f\"Warning: {folder_path} does not exist.\")\n            continue\n        \n        for filename in os.listdir(folder_path):\n            if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n                continue  # Skip non-image files\n            \n            img_path = os.path.join(folder_path, filename)\n            img = cv2.imread(img_path)\n            \n            if img is None:\n                print(f\"Warning: Unable to read {img_path}\")\n                continue  # Skip unreadable images\n            \n            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            images.append(img_rgb)\n            labels.append(new_label_map[idx])  # Assign new label\n    \n    return np.array(images), np.array(labels)\n\n\n\n\n# Exclude labels 1 (neutral), 2 (happy), and 6 (disgust)\nexcluded_labels = {1, 3, 7}\n\n# New sequential label mapping\nnew_label_map = {2: 1, 4: 2, 5: 3, 6: 4}  # Mapping for the remaining labels\n\n# Load train and test datasets\ntrain_images, train_labels = load_data('/kaggle/input/raf-db-dataset/DATASET/train', label_map, excluded_labels, new_label_map)\ntest_images, test_labels = load_data('/kaggle/input/raf-db-dataset/DATASET/test', label_map, excluded_labels, new_label_map)\n\n# Print dataset distribution after remapping\ntrain_label_counts = Counter(train_labels)\ntest_label_counts = Counter(test_labels)\n\nprint(\"Train label counts:\", train_label_counts)\nprint(\"Test label counts:\", test_label_counts)\nprint(\"Train images shape:\", train_images.shape)\nprint(\"Test images shape:\", test_images.shape)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate the total number of images\ntotal_images = len(train_images) + len(test_images)\n\n# Calculate percentages\ntrain_percentage = (len(train_images) / total_images) * 100\ntest_percentage = (len(test_images) / total_images) * 100\n\n# Data for pie chart\nlabels = ['Training Data', 'Testing Data']\nsizes = [train_percentage, test_percentage]\ncolors = ['cornflowerblue', 'lightcoral']\n\n# Plot the pie chart\n\nplt.figure(figsize=(3, 3))\nplt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\nplt.title('Percentage Distribution of Training and Testing Data')\nplt.axis('equal')  \nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import Counter\n\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count the distribution of classes in train and test datasets\ntrain_label_counts = Counter(train_labels)\ntest_label_counts = Counter(test_labels)\nprint('train_label_counts ',train_label_counts)\n# Convert to sorted lists for plotting\ntrain_classes = sorted(train_label_counts.keys())\ntrain_counts = [train_label_counts[cls] for cls in train_classes]\n\ntest_classes = sorted(test_label_counts.keys())\ntest_counts = [test_label_counts[cls] for cls in test_classes]\nprint('test_counts',test_counts)\n# Calculate the total number of examples in train and test datasets\ntotal_train = sum(train_counts)\ntotal_test = sum(test_counts)\n\n# Calculate percentages for train and test datasets\ntrain_percentages = [(count / total_train) * 100 for count in train_counts]\ntest_percentages = [(count / total_test) * 100 for count in test_counts]\n\n# Plot the distribution with percentages\nplt.figure(figsize=(8, 6))\nx = range(len(classes))\nbar_width = 0.35\n\nplt.bar(x, train_counts, width=bar_width, label=\"Train\", alpha=0.7, color=\"cornflowerblue\")\nplt.bar([p + bar_width for p in x], test_counts, width=bar_width, label=\"Test\", alpha=0.7, color=\"crimson\")\n\n# Annotate percentages on bars\nfor i, (train_count, test_count) in enumerate(zip(train_counts, test_counts)):\n    plt.text(i, train_count + 0.005 * total_train, f\"{train_percentages[i]:.1f}%\", ha='center', color=\"blue\", fontsize=9)\n    plt.text(i + bar_width, test_count + 0.005 * total_test, f\"{test_percentages[i]:.1f}%\", ha='center', color=\"red\", fontsize=9)\n\n# Add labels and title\nplt.xticks([p + bar_width / 2 for p in x], classes, rotation=45)\nplt.xlabel(\"Emotion Class\")\nplt.ylabel(\"Number of Examples\")\nplt.title(\"Distribution of Examples in Train and Test Datasets with Percentages\")\nplt.legend()\nplt.tight_layout()\n\n# Show the plot\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train = np.concatenate([train_images, test_images], axis=0)\nY_train = np.concatenate([train_labels, test_labels], axis=0)\n\n# Display the shapes to confirm\nprint(X_train.shape)\nprint(Y_train.shape)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count the distribution of classes in the resampled train dataset\ntrain_label_counts_resampled = Counter(Y_train)\n    \n# Convert to sorted lists for plotting\ntrain_classes_resampled = sorted(train_label_counts_resampled.keys())\ntrain_counts_resampled = [train_label_counts_resampled[cls] for cls in train_classes_resampled]\n# Plot the distribution\nplt.figure(figsize=(6, 3))\nx_labels = [ 'Fear', 'Happy', 'Sad', 'Angry']\n    \n# Bar plot for the resampled distribution\nplt.bar(x_labels, train_counts_resampled, color=\"steelblue\")\n    \n# Add labels and title\nplt.xlabel(\"Emotion Class\")\nplt.ylabel(\"Number of Examples\")\nplt.title('')\nplt.tight_layout()\n    \n# Show the plot\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_class_distribution(y, title):\n    # Count the distribution of classes in the resampled train dataset\n    train_label_counts_resampled = Counter(y)\n    \n    # Convert to sorted lists for plotting\n    train_classes_resampled = sorted(train_label_counts_resampled.keys())\n    train_counts_resampled = [train_label_counts_resampled[cls] for cls in train_classes_resampled]\n    \n    # Plot the distribution\n    plt.figure(figsize=(6, 3))\n    x_labels = [ 'Fear', 'Happy', 'Sad', 'Angry']\n    \n    # Bar plot for the resampled distribution\n    plt.bar(x_labels, train_counts_resampled, color=\"steelblue\")\n    \n    # Add labels and title\n    plt.xlabel(\"Emotion Class\")\n    plt.ylabel(\"Number of Examples\")\n    plt.title(title)\n    plt.tight_layout()\n    \n    # Show the plot\n    plt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to reduce the size of a specific class in the dataset\ndef reduce_class(X, y, target_class, target_size):\n    # Separate the target class\n    class_indices = np.where(y == target_class)[0]\n    non_class_indices = np.where(y != target_class)[0]\n    \n    # Randomly sample the target class to the desired size\n    reduced_class_indices = np.random.choice(class_indices, target_size, replace=False)\n    \n    # Combine the reduced class with the other classes\n    final_indices = np.concatenate([reduced_class_indices, non_class_indices])\n    X_reduced = X[final_indices]\n    y_reduced = y[final_indices]\n    \n    return X_reduced, y_reduced\n\ntarget_class = 2  # The 'happy' class\ntarget_size = 3500\nX_train_reduced, y_train_reduced = reduce_class(X_train, Y_train, target_class, target_size)\n# Plot the new distribution after reduction\nplot_class_distribution(y_train_reduced, \"Class Distribution After Reduction\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def augment_classes(images, labels, target_counts):\n    # Initialisation de la génération d'images augmentées\n    datagen = ImageDataGenerator(\n        rotation_range=10,             \n        width_shift_range=0.1,         \n        height_shift_range=0.1,  \n        zoom_range=0.1,\n        vertical_flip=False,               \n        horizontal_flip=True, \n        channel_shift_range=50.0,\n        fill_mode='nearest'\n    )\n\n    augmented_images = images.copy()  # Nous copions les images pour conserver les originales\n    augmented_labels = labels.copy()  # Idem pour les labels\n\n    # Pour chaque classe, nous augmentons le nombre d'échantillons\n    for target_class, target_count in target_counts.items():\n        # Filtrage des images et labels pour la classe cible\n        class_images = images[labels == target_class]\n        class_labels = labels[labels == target_class]\n        # Calcul du nombre d'échantillons à générer\n        augment_count = target_count - len(class_images)\n\n        if augment_count > 0:\n            print(f'Classe {target_class}:  has {len(class_images)} samples  are agumented samples are {augment_count} .')\n\n            # Création d'un itérateur pour la classe cible\n            class_images_augmented = []\n            class_labels_augmented = []\n\n            # Appliquer l'augmentation de manière itérative\n            for batch in datagen.flow(class_images, batch_size=1, seed=42):\n                aug_image = batch[0].astype(np.uint8)\n                class_images_augmented.append(aug_image)\n                class_labels_augmented.append(target_class)\n                \n                # Arrêter quand le nombre souhaité d'images augmentées est atteint\n                if len(class_images_augmented) >= augment_count:\n                    break\n                    # Ajouter les images augmentées au jeu de données original\n            augmented_images = np.vstack((augmented_images, np.array(class_images_augmented)))\n            augmented_labels = np.hstack((augmented_labels, np.array(class_labels_augmented)))\n\n    return augmented_images, augmented_labels\n\n# Example usage\ntarget_counts = {1: 3500, 3: 3500, 4: 3500, }  # Target counts for each class\nX_train_augmented, y_train_augmented = augment_classes(X_train_reduced, y_train_reduced, target_counts)\n\n# Visualize the class distribution after augmentation\nplot_class_distribution(y_train_augmented, \"Class Distribution After Augmentation\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.866Z"}},"outputs":[],"execution_count":null},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV,train_test_split\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the data into training and testing sets (75% train, 25% test)\nX_train, X_test, Y_train, Y_test = train_test_split(X_train_augmented, \n                                                    y_train_augmented, \n                                                    test_size=0.25, \n                                                    shuffle=True,\n                                                    random_state=42)\n\n# Calculate the total number of images\ntotal_images = len(X_train) + len(X_test)\n\n# Calculate percentages\ntrain_percentage = (len(X_train) / total_images) * 100\ntest_percentage = (len(X_test) / total_images) * 100\n\n# Data for pie chart\nlabels = ['Training Data', 'Testing Data']\nsizes = [train_percentage, test_percentage]\ncolors = ['cornflowerblue', 'lightcoral']\n\n# Plot the pie chart\nplt.figure(figsize=(3, 3))\nplt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90, colors=colors)\nplt.title('Percentage Distribution of Training and Testing Data')\nplt.axis('equal')  \nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def normalize_images(images):\n    # Normalize pixel values to [0, 1]\n    return images / 255.0\n\ntrain_images_normalized = normalize_images(X_train)\ntest_images_normalized = normalize_images(X_test)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def reshape_images(images, model_type='CNN'):\n        return images.reshape((images.shape[0], 100, 100, 3))\n\ntrain_images_SVMreshaped = reshape_images(train_images_normalized, model_type='SVM')\ntest_images_SVMreshaped = reshape_images(test_images_normalized, model_type='SVM')\n\ntrain_images_CNNreshaped = reshape_images(train_images_normalized, model_type='CNN')\ntest_images_CNNreshaped = reshape_images(test_images_normalized, model_type='CNN')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert labels to categorical for CNN\nY_train_cat = to_categorical(Y_train - 1, num_classes=len(classes))\nY_test_cat = to_categorical(Y_test - 1, num_classes=len(classes))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rotation_range=20,             \n    width_shift_range=0.1,         \n    height_shift_range=0.1,  \n    vertical_flip=False,               \n    horizontal_flip=True, \n    fill_mode='nearest'\n)\n\n# Create the generator for training\ntrain_generator = datagen.flow(train_images_CNNreshaped, Y_train_cat, batch_size=64)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import Model, Sequential, save_model\n\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the CNN model\ncnn_model = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(test_images_CNNreshaped[0].shape)),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    \n    Conv2D(512, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    \n    Flatten(),\n    Dense(512, activation='relu'),\n    Dropout(0.5),\n\n    Dense(len(classes), activation='softmax')\n])\n\ncnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\ncnn_model.summary()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train the CNN model\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=10, min_delta=0.0001, verbose=1) \nearly_stop = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)  \ncheckpoint = ModelCheckpoint(filepath='best_CNNModel.keras', monitor='val_accuracy', save_best_only=True, verbose=1) \n\nCNN_History = cnn_model.fit(\n    train_generator,\n    epochs=60, \n    batch_size = 32,\n    validation_data=(test_images_CNNreshaped, Y_test_cat), \n    callbacks=[reduce_lr, early_stop, checkpoint]\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-27T17:08:08.867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}